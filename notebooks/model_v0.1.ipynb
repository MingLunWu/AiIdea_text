{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model V0.1 \n",
    "@ 2020/10/29\n",
    "\n",
    "初步套用 `BERT-Chinese` 進行訓練，使用 `Down-sample`的方式來降低 `Other Class`的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"/home/clll/AiIdea_text/\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pd.read_csv(\"./data/train_text.csv\")\n",
    "train_label = pd.read_csv(\"./data/train_label.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 進行斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為尚未進行裁切，所以會顯示警告。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4212 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2653 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3102 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1791 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2214 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3504 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1934 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1646 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3636 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2052 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2604 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1810 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3464 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1634 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1703 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1598 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3370 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4295 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1589 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3756 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2971 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1761 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (957 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2460 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5277 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (883 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2031 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1872 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2977 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1739 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2454 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2100 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1608 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3459 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2610 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1719 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1695 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2520 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2169 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2361 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1001 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1660 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2405 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1687 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3082 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3690 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (985 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2349 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4080 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2431 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1817 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2076 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2275 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2748 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (955 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1778 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1765 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1848 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2076 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4831 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3234 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2185 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3336 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2025 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3160 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3287 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3491 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2679 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1521 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2279 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2827 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1792 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1686 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7310 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1643 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4066 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5639 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2862 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2616 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3930 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "train_text['text_encoded'] = train_text.text.apply(lambda x: tokenizer.encode(list(x), add_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>醫師：啊回去還好嗎？民眾：欸，還是虛虛的，但。醫師：欸，真的。民眾：好險好險。坦白講我剛回去...</td>\n",
       "      <td>[7015, 2374, 8038, 1557, 1726, 1343, 6917, 196...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>醫師：阿阿嬤她好像說有，前天又有在發燒喔。家屬：對阿都，有時候都會一天她會燒，誒，可是她這樣...</td>\n",
       "      <td>[7015, 2374, 8038, 7350, 7350, 2085, 1961, 196...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>民眾：也有點不舒服，可是就是腰這邊有也一點點痛，我脫起來我想……。醫師：來我看一下。民眾：看...</td>\n",
       "      <td>[3696, 4707, 8038, 738, 3300, 7953, 679, 5653,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>醫師：謝謝你這樣幫忙他們這樣，那最近還好嗎？民眾：就是因為不太好所以才要再回診，因為我為甚麼...</td>\n",
       "      <td>[7015, 2374, 8038, 6342, 6342, 872, 6857, 3564...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>醫師：那個，吃藥還Ok嗎？民眾：OK。醫師：沒什麼問題？民眾：沒有。醫師：我們這次CD4是3...</td>\n",
       "      <td>[7015, 2374, 8038, 6929, 943, 8024, 1391, 5973...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>醫師：所以今天是爲了暴露前預防嘛？民衆：嗯。醫師：你身邊有其他人在吃的嗎？民衆：沒有欸。醫師...</td>\n",
       "      <td>[7015, 2374, 8038, 2792, 809, 791, 1921, 3221,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>醫師：所以你這個月，你是任務型嗎？民眾：對。醫師：阿吃幾組？民眾：我印象中應該有4組。醫師：...</td>\n",
       "      <td>[7015, 2374, 8038, 2792, 809, 872, 6857, 943, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>醫師：這個月還好嗎？民衆：這個月還好，上班比較無聊而已。醫師：還可以，上班沒有人有聊的啊。所...</td>\n",
       "      <td>[7015, 2374, 8038, 6857, 943, 3299, 6917, 1962...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>醫師：那所以今天是要這個暴露前預防？民眾：對。醫師：欸……你，怎麼知道我們的？民眾：因為我是...</td>\n",
       "      <td>[7015, 2374, 8038, 6929, 2792, 809, 791, 1921,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>醫師：那所以你現在藥是有繼續在吃？民眾：有。醫師：那比方說像是過去這個月你有性行為嗎？民眾：...</td>\n",
       "      <td>[7015, 2374, 8038, 6929, 2792, 809, 872, 4412,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id                                               text  \\\n",
       "0             0  醫師：啊回去還好嗎？民眾：欸，還是虛虛的，但。醫師：欸，真的。民眾：好險好險。坦白講我剛回去...   \n",
       "1             1  醫師：阿阿嬤她好像說有，前天又有在發燒喔。家屬：對阿都，有時候都會一天她會燒，誒，可是她這樣...   \n",
       "2             2  民眾：也有點不舒服，可是就是腰這邊有也一點點痛，我脫起來我想……。醫師：來我看一下。民眾：看...   \n",
       "3             3  醫師：謝謝你這樣幫忙他們這樣，那最近還好嗎？民眾：就是因為不太好所以才要再回診，因為我為甚麼...   \n",
       "4             4  醫師：那個，吃藥還Ok嗎？民眾：OK。醫師：沒什麼問題？民眾：沒有。醫師：我們這次CD4是3...   \n",
       "..          ...                                                ...   \n",
       "115         115  醫師：所以今天是爲了暴露前預防嘛？民衆：嗯。醫師：你身邊有其他人在吃的嗎？民衆：沒有欸。醫師...   \n",
       "116         116  醫師：所以你這個月，你是任務型嗎？民眾：對。醫師：阿吃幾組？民眾：我印象中應該有4組。醫師：...   \n",
       "117         117  醫師：這個月還好嗎？民衆：這個月還好，上班比較無聊而已。醫師：還可以，上班沒有人有聊的啊。所...   \n",
       "118         118  醫師：那所以今天是要這個暴露前預防？民眾：對。醫師：欸……你，怎麼知道我們的？民眾：因為我是...   \n",
       "119         119  醫師：那所以你現在藥是有繼續在吃？民眾：有。醫師：那比方說像是過去這個月你有性行為嗎？民眾：...   \n",
       "\n",
       "                                          text_encoded  \n",
       "0    [7015, 2374, 8038, 1557, 1726, 1343, 6917, 196...  \n",
       "1    [7015, 2374, 8038, 7350, 7350, 2085, 1961, 196...  \n",
       "2    [3696, 4707, 8038, 738, 3300, 7953, 679, 5653,...  \n",
       "3    [7015, 2374, 8038, 6342, 6342, 872, 6857, 3564...  \n",
       "4    [7015, 2374, 8038, 6929, 943, 8024, 1391, 5973...  \n",
       "..                                                 ...  \n",
       "115  [7015, 2374, 8038, 2792, 809, 791, 1921, 3221,...  \n",
       "116  [7015, 2374, 8038, 2792, 809, 872, 6857, 943, ...  \n",
       "117  [7015, 2374, 8038, 6857, 943, 3299, 6917, 1962...  \n",
       "118  [7015, 2374, 8038, 6929, 2792, 809, 791, 1921,...  \n",
       "119  [7015, 2374, 8038, 6929, 2792, 809, 872, 4412,...  \n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "順便觀察每篇對話的character數量 (接下來可以發現 Label 極度不平均)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     120.000000\n",
       "mean     2110.950000\n",
       "std      1133.878299\n",
       "min       568.000000\n",
       "25%      1286.750000\n",
       "50%      1763.000000\n",
       "75%      2625.250000\n",
       "max      7310.000000\n",
       "Name: text_encoded, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.text_encoded.apply(lambda x: len(x)).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整理 Label 欄位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>entity_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>71</td>\n",
       "      <td>前天</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>前天</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>738</td>\n",
       "      <td>740</td>\n",
       "      <td>85</td>\n",
       "      <td>med_exam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>741</td>\n",
       "      <td>744</td>\n",
       "      <td>102</td>\n",
       "      <td>med_exam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>809</td>\n",
       "      <td>811</td>\n",
       "      <td>前年</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>119</td>\n",
       "      <td>1136</td>\n",
       "      <td>1138</td>\n",
       "      <td>彰化</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>119</td>\n",
       "      <td>1143</td>\n",
       "      <td>1145</td>\n",
       "      <td>彰化</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>119</td>\n",
       "      <td>1173</td>\n",
       "      <td>1177</td>\n",
       "      <td>彰化醫院</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>119</td>\n",
       "      <td>1216</td>\n",
       "      <td>1221</td>\n",
       "      <td>陳明明醫師</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>119</td>\n",
       "      <td>1250</td>\n",
       "      <td>1255</td>\n",
       "      <td>陳明明醫師</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2136 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id  start_position  end_position entity_text entity_type\n",
       "0              0              69            71          前天        time\n",
       "1              0              75            77          前天        time\n",
       "2              0             738           740          85    med_exam\n",
       "3              0             741           744         102    med_exam\n",
       "4              0             809           811          前年        time\n",
       "...          ...             ...           ...         ...         ...\n",
       "2131         119            1136          1138          彰化    location\n",
       "2132         119            1143          1145          彰化    location\n",
       "2133         119            1173          1177        彰化醫院    location\n",
       "2134         119            1216          1221       陳明明醫師        name\n",
       "2135         119            1250          1255       陳明明醫師        name\n",
       "\n",
       "[2136 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "for a_id in train_text.article_id.iloc:\n",
    "    text_encoded = train_text.query(\"article_id=={}\".format(a_id)).iloc[0].text_encoded\n",
    "    label = [\"other\"] * len(text_encoded)\n",
    "    # ground truth\n",
    "    gt = train_label.query(\"article_id=={}\".format(a_id))\n",
    "\n",
    "    for _, a_gt in gt.iterrows():\n",
    "        start_pos = a_gt.start_position\n",
    "        end_pos = a_gt.end_position\n",
    "        entity_type = a_gt.entity_type\n",
    "        position = list(range(int(start_pos), int(end_pos)))\n",
    "        for x, y in zip(position, [entity_type] * len(position)):\n",
    "            label[x] = y\n",
    "    result[a_id] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>[other, other, other, other, other, time, time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>[other, other, other, other, other, other, tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>[other, other, other, time, time, time, other,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>[other, other, other, other, other, other, tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id                                              label\n",
       "0             0  [other, other, other, other, other, other, oth...\n",
       "1             1  [other, other, other, other, other, other, oth...\n",
       "2             2  [other, other, other, other, other, other, oth...\n",
       "3             3  [other, other, other, other, other, other, oth...\n",
       "4             4  [other, other, other, other, other, other, oth...\n",
       "..          ...                                                ...\n",
       "115         115  [other, other, other, other, other, time, time...\n",
       "116         116  [other, other, other, other, other, other, tim...\n",
       "117         117  [other, other, other, time, time, time, other,...\n",
       "118         118  [other, other, other, other, other, other, tim...\n",
       "119         119  [other, other, other, other, other, other, oth...\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_preprocessed = pd.DataFrame({\"article_id\":result.keys(), \"label\":result.values()})\n",
    "label_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將label轉換成index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other             246748\n",
       "time                4578\n",
       "med_exam             606\n",
       "name                 453\n",
       "location             401\n",
       "money                272\n",
       "contact               98\n",
       "profession            53\n",
       "family                53\n",
       "ID                    23\n",
       "clinical_event        20\n",
       "education              6\n",
       "organization           3\n",
       "Name: code, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = list()\n",
    "for i in label_preprocessed.label:\n",
    "    temp += i\n",
    "count = pd.DataFrame({'code':temp}).code.value_counts()\n",
    "label2idx = {v:k for (k,v) in enumerate(count.keys())}\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'other': 0,\n",
       " 'time': 1,\n",
       " 'med_exam': 2,\n",
       " 'name': 3,\n",
       " 'location': 4,\n",
       " 'money': 5,\n",
       " 'contact': 6,\n",
       " 'profession': 7,\n",
       " 'family': 8,\n",
       " 'ID': 9,\n",
       " 'clinical_event': 10,\n",
       " 'education': 11,\n",
       " 'organization': 12}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_preprocessed[\"label_encoded\"] = label_preprocessed.label.apply(lambda x:[label2idx[ele] for ele in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>[other, other, other, other, other, time, time...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>[other, other, other, other, other, other, tim...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>[other, other, other, time, time, time, other,...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>[other, other, other, other, other, other, tim...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id                                              label  \\\n",
       "0             0  [other, other, other, other, other, other, oth...   \n",
       "1             1  [other, other, other, other, other, other, oth...   \n",
       "2             2  [other, other, other, other, other, other, oth...   \n",
       "3             3  [other, other, other, other, other, other, oth...   \n",
       "4             4  [other, other, other, other, other, other, oth...   \n",
       "..          ...                                                ...   \n",
       "115         115  [other, other, other, other, other, time, time...   \n",
       "116         116  [other, other, other, other, other, other, tim...   \n",
       "117         117  [other, other, other, time, time, time, other,...   \n",
       "118         118  [other, other, other, other, other, other, tim...   \n",
       "119         119  [other, other, other, other, other, other, oth...   \n",
       "\n",
       "                                         label_encoded  \n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "..                                                 ...  \n",
       "115  [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "116  [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "117  [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...  \n",
       "118  [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "119  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把處理好的文章跟label Merge成同一個Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_encoded</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>醫師：啊回去還好嗎？民眾：欸，還是虛虛的，但。醫師：欸，真的。民眾：好險好險。坦白講我剛回去...</td>\n",
       "      <td>[7015, 2374, 8038, 1557, 1726, 1343, 6917, 196...</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>醫師：阿阿嬤她好像說有，前天又有在發燒喔。家屬：對阿都，有時候都會一天她會燒，誒，可是她這樣...</td>\n",
       "      <td>[7015, 2374, 8038, 7350, 7350, 2085, 1961, 196...</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>民眾：也有點不舒服，可是就是腰這邊有也一點點痛，我脫起來我想……。醫師：來我看一下。民眾：看...</td>\n",
       "      <td>[3696, 4707, 8038, 738, 3300, 7953, 679, 5653,...</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>醫師：謝謝你這樣幫忙他們這樣，那最近還好嗎？民眾：就是因為不太好所以才要再回診，因為我為甚麼...</td>\n",
       "      <td>[7015, 2374, 8038, 6342, 6342, 872, 6857, 3564...</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>醫師：那個，吃藥還Ok嗎？民眾：OK。醫師：沒什麼問題？民眾：沒有。醫師：我們這次CD4是3...</td>\n",
       "      <td>[7015, 2374, 8038, 6929, 943, 8024, 1391, 5973...</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>醫師：所以今天是爲了暴露前預防嘛？民衆：嗯。醫師：你身邊有其他人在吃的嗎？民衆：沒有欸。醫師...</td>\n",
       "      <td>[7015, 2374, 8038, 2792, 809, 791, 1921, 3221,...</td>\n",
       "      <td>[other, other, other, other, other, time, time...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>醫師：所以你這個月，你是任務型嗎？民眾：對。醫師：阿吃幾組？民眾：我印象中應該有4組。醫師：...</td>\n",
       "      <td>[7015, 2374, 8038, 2792, 809, 872, 6857, 943, ...</td>\n",
       "      <td>[other, other, other, other, other, other, tim...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>醫師：這個月還好嗎？民衆：這個月還好，上班比較無聊而已。醫師：還可以，上班沒有人有聊的啊。所...</td>\n",
       "      <td>[7015, 2374, 8038, 6857, 943, 3299, 6917, 1962...</td>\n",
       "      <td>[other, other, other, time, time, time, other,...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>醫師：那所以今天是要這個暴露前預防？民眾：對。醫師：欸……你，怎麼知道我們的？民眾：因為我是...</td>\n",
       "      <td>[7015, 2374, 8038, 6929, 2792, 809, 791, 1921,...</td>\n",
       "      <td>[other, other, other, other, other, other, tim...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>醫師：那所以你現在藥是有繼續在吃？民眾：有。醫師：那比方說像是過去這個月你有性行為嗎？民眾：...</td>\n",
       "      <td>[7015, 2374, 8038, 6929, 2792, 809, 872, 4412,...</td>\n",
       "      <td>[other, other, other, other, other, other, oth...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id                                               text  \\\n",
       "0             0  醫師：啊回去還好嗎？民眾：欸，還是虛虛的，但。醫師：欸，真的。民眾：好險好險。坦白講我剛回去...   \n",
       "1             1  醫師：阿阿嬤她好像說有，前天又有在發燒喔。家屬：對阿都，有時候都會一天她會燒，誒，可是她這樣...   \n",
       "2             2  民眾：也有點不舒服，可是就是腰這邊有也一點點痛，我脫起來我想……。醫師：來我看一下。民眾：看...   \n",
       "3             3  醫師：謝謝你這樣幫忙他們這樣，那最近還好嗎？民眾：就是因為不太好所以才要再回診，因為我為甚麼...   \n",
       "4             4  醫師：那個，吃藥還Ok嗎？民眾：OK。醫師：沒什麼問題？民眾：沒有。醫師：我們這次CD4是3...   \n",
       "..          ...                                                ...   \n",
       "115         115  醫師：所以今天是爲了暴露前預防嘛？民衆：嗯。醫師：你身邊有其他人在吃的嗎？民衆：沒有欸。醫師...   \n",
       "116         116  醫師：所以你這個月，你是任務型嗎？民眾：對。醫師：阿吃幾組？民眾：我印象中應該有4組。醫師：...   \n",
       "117         117  醫師：這個月還好嗎？民衆：這個月還好，上班比較無聊而已。醫師：還可以，上班沒有人有聊的啊。所...   \n",
       "118         118  醫師：那所以今天是要這個暴露前預防？民眾：對。醫師：欸……你，怎麼知道我們的？民眾：因為我是...   \n",
       "119         119  醫師：那所以你現在藥是有繼續在吃？民眾：有。醫師：那比方說像是過去這個月你有性行為嗎？民眾：...   \n",
       "\n",
       "                                          text_encoded  \\\n",
       "0    [7015, 2374, 8038, 1557, 1726, 1343, 6917, 196...   \n",
       "1    [7015, 2374, 8038, 7350, 7350, 2085, 1961, 196...   \n",
       "2    [3696, 4707, 8038, 738, 3300, 7953, 679, 5653,...   \n",
       "3    [7015, 2374, 8038, 6342, 6342, 872, 6857, 3564...   \n",
       "4    [7015, 2374, 8038, 6929, 943, 8024, 1391, 5973...   \n",
       "..                                                 ...   \n",
       "115  [7015, 2374, 8038, 2792, 809, 791, 1921, 3221,...   \n",
       "116  [7015, 2374, 8038, 2792, 809, 872, 6857, 943, ...   \n",
       "117  [7015, 2374, 8038, 6857, 943, 3299, 6917, 1962...   \n",
       "118  [7015, 2374, 8038, 6929, 2792, 809, 791, 1921,...   \n",
       "119  [7015, 2374, 8038, 6929, 2792, 809, 872, 4412,...   \n",
       "\n",
       "                                                 label  \\\n",
       "0    [other, other, other, other, other, other, oth...   \n",
       "1    [other, other, other, other, other, other, oth...   \n",
       "2    [other, other, other, other, other, other, oth...   \n",
       "3    [other, other, other, other, other, other, oth...   \n",
       "4    [other, other, other, other, other, other, oth...   \n",
       "..                                                 ...   \n",
       "115  [other, other, other, other, other, time, time...   \n",
       "116  [other, other, other, other, other, other, tim...   \n",
       "117  [other, other, other, time, time, time, other,...   \n",
       "118  [other, other, other, other, other, other, tim...   \n",
       "119  [other, other, other, other, other, other, oth...   \n",
       "\n",
       "                                         label_encoded  \n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "..                                                 ...  \n",
       "115  [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "116  [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "117  [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...  \n",
       "118  [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "119  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df = pd.merge(train_text, label_preprocessed)\n",
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.to_csv(\"./data/preprocessed_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備 Tensorflow Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text, all_label = list(), list()\n",
    "\n",
    "for _, row in preprocessed_df.iterrows():\n",
    "    all_text += row.text_encoded\n",
    "    all_label += row.label_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     246748\n",
       "1       4578\n",
       "2        606\n",
       "3        453\n",
       "4        401\n",
       "5        272\n",
       "6         98\n",
       "8         53\n",
       "7         53\n",
       "9         23\n",
       "10        20\n",
       "11         6\n",
       "12         3\n",
       "Name: code, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'code':all_label}).code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_num = 0\n",
    "\n",
    "while remove_num <= 240000:\n",
    "    idx = random.randint(0, len(all_label)-1)\n",
    "    if all_label[idx] == 0:\n",
    "        all_text.pop(idx)\n",
    "        all_label.pop(idx)\n",
    "        remove_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6747\n",
       "1     4578\n",
       "2      606\n",
       "3      453\n",
       "4      401\n",
       "5      272\n",
       "6       98\n",
       "7       53\n",
       "8       53\n",
       "9       23\n",
       "10      20\n",
       "11       6\n",
       "12       3\n",
       "Name: code, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'code':all_label}).code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_512, label_512 = list(), list()\n",
    "text, label = list(), list()\n",
    "for idx, (a_text, a_label) in enumerate(zip(all_text, all_label)):\n",
    "    text_512.append(a_text)\n",
    "    label_512.append(a_label)\n",
    "    \n",
    "    if len(text_512) == 512:\n",
    "        text.append(text_512)\n",
    "        label.append(label_512)\n",
    "        text_512, label_512 = list(), list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text), len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = random.sample(range(len(text)), k=int(len(text) * 0.9))\n",
    "valid_idx = list(set(range(len(text))) - set(train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = [text[x] for x in train_idx]\n",
    "train_label = [label[x] for x in train_idx]\n",
    "valid_text = [text[x] for x in valid_idx]\n",
    "valid_label = [label[x] for x in valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 23, 3, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_text), len(train_label), len(valid_text), len(valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_tensor_slices((train_text, train_label))\n",
    "valid_dataset = Dataset.from_tensor_slices((valid_text, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建構模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-chinese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_zh = TFAutoModel.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(512,), dtype='int32')\n",
    "last_hidden_state, _ = bert_zh(input_ids)\n",
    "X = tf.keras.layers.Dense(384, activation='relu')(last_hidden_state)\n",
    "X = tf.keras.layers.Dropout(0.5)(X)\n",
    "X = tf.keras.layers.Dense(192, activation='relu')(X)\n",
    "X = tf.keras.layers.Dense(13, activation='sigmoid')(X)\n",
    "model = tf.keras.Model(inputs=input_ids, outputs=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 512)]             0         \n",
      "_________________________________________________________________\n",
      "tf_bert_model_1 (TFBertModel ((None, 512, 768), (None, 102267648 \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512, 384)          295296    \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 512, 384)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512, 192)          73920     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512, 13)           2509      \n",
      "=================================================================\n",
      "Total params: 102,639,373\n",
      "Trainable params: 371,725\n",
      "Non-trainable params: 102,267,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.get_layer('tf_bert_model_1').trainable=False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_actual, y_pred):\n",
    "    loss = tf.losses.sparse_categorical_crossentropy(y_actual, y_pred)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=custom_loss, optimizer='adam', metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 512) for input Tensor(\"input_2:0\", shape=(None, 512), dtype=int32), but it was called on an input with incompatible shape (512, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 512) for input Tensor(\"input_2:0\", shape=(None, 512), dtype=int32), but it was called on an input with incompatible shape (512, 1).\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 1.6311 - sparse_categorical_accuracy: 0.4676WARNING:tensorflow:Model was constructed with shape (None, 512) for input Tensor(\"input_2:0\", shape=(None, 512), dtype=int32), but it was called on an input with incompatible shape (512, 1).\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 1.6179 - sparse_categorical_accuracy: 0.4748 - val_loss: 1.2327 - val_sparse_categorical_accuracy: 0.5117\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.3443 - sparse_categorical_accuracy: 0.5062 - val_loss: 1.2016 - val_sparse_categorical_accuracy: 0.5117\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 1.3106 - sparse_categorical_accuracy: 0.5062 - val_loss: 1.1409 - val_sparse_categorical_accuracy: 0.5117\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.2836 - sparse_categorical_accuracy: 0.5062 - val_loss: 1.1084 - val_sparse_categorical_accuracy: 0.5117\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.2540 - sparse_categorical_accuracy: 0.5062 - val_loss: 1.0657 - val_sparse_categorical_accuracy: 0.5117\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.2301 - sparse_categorical_accuracy: 0.5062 - val_loss: 0.9814 - val_sparse_categorical_accuracy: 0.5117\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.2168 - sparse_categorical_accuracy: 0.5063 - val_loss: 0.9834 - val_sparse_categorical_accuracy: 0.5117\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.2079 - sparse_categorical_accuracy: 0.5064 - val_loss: 0.9782 - val_sparse_categorical_accuracy: 0.5117\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.2038 - sparse_categorical_accuracy: 0.5066 - val_loss: 0.9680 - val_sparse_categorical_accuracy: 0.5117\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.1873 - sparse_categorical_accuracy: 0.5066 - val_loss: 0.9605 - val_sparse_categorical_accuracy: 0.5117\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=train_dataset,\n",
    "    batch_size=4, \n",
    "    epochs=10,\n",
    "    validation_data=valid_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb43eb31fd0>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = iter(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
       "array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 5, 5, 5, 3, 3, 0, 0, 0, 0, 0, 3, 3, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1], dtype=int32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels = next(temp)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict(inputs)\n",
    "predict.argmax(axis=-1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9986744e-01, 9.9742800e-01, 3.0816698e-03, ..., 6.3355156e-04,\n",
       "        1.1422102e-04, 6.4305743e-05],\n",
       "       [9.9995136e-01, 9.9934942e-01, 3.6635160e-02, ..., 4.5767397e-04,\n",
       "        4.4226501e-05, 1.6486036e-05],\n",
       "       [9.9997902e-01, 5.5352718e-01, 1.4056788e-03, ..., 3.0925512e-04,\n",
       "        1.6119082e-04, 1.2548304e-05],\n",
       "       ...,\n",
       "       [9.9827981e-01, 8.7569797e-01, 1.4859860e-01, ..., 3.9949128e-03,\n",
       "        1.0312947e-03, 1.0180547e-03],\n",
       "       [9.9935240e-01, 7.8830504e-01, 1.1869335e-01, ..., 2.3154656e-03,\n",
       "        3.3985535e-04, 3.3712824e-04],\n",
       "       [9.9941969e-01, 9.7173417e-01, 1.9590838e-02, ..., 3.5301952e-03,\n",
       "        1.3286283e-03, 8.7071367e-04]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.reshape(512,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 結論 \n",
    "V0 版本的模型，可能因為Class Imbalanced的關係，預測出來全部都是0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
